---
title: 'Midterm Project'
subtitle: 'CUNY DATA 624 | 2023 Summer I'
author: 'Group 3: Daniel Sullivan, Jeff Parks, Lwin Shwe, Matthew Katz'
# abstract: 'abstract text'
# format:
#   docx:
#     highlight-style: arrow
#     number-sections: false
#     number-depth: 2
#     reference-doc: ../../../templates/quarto-word-template.docx
#     toc: true
#     toc-depth: 1
#     toc-title: Contents
editor: visual
execute:
  echo: false
  eval: true
  include: true
  message: false
  warning: false
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
page-layout: article
---

```{r setup}
# libraries
library(tidyverse)
library(fpp2)
library(readxl)
library(zoo)
library(seasonal)
library(kableExtra)
library(MLmetrics)
library(imputeTS)

# ggplot
theme_set(theme_light())
```

```{r functions}
nice_table <- function(df, cap=NULL, cols=NULL, dig=3, fw=F){
  if (is.null(cols)) {c <- colnames(df)} else {c <- cols}
  table <- df %>% 
    kable(caption=cap, col.names=c, digits=dig) %>% 
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      html_font = 'monospace',
      full_width = fw)
  return(table)
}
```

```{r load-data}
# load data
df <- read_xls('../data/Data Set for Class.xls', sheet='Set for Class') %>%
  mutate(Date = as.Date(SeriesInd-2, origin = '1900-01-01'))
```

```{r}
# set up timeseries

df_s01 <- df %>%
  filter(category == 'S01') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var01,Var02)) %>%
  head(1622)

df_s02 <- df %>%
  filter(category == 'S02') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var02,Var03)) %>%
  head(1622)

df_s03 <- df %>%
  filter(category == 'S03') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var05,Var07)) %>%
  head(1622)

df_s04 <- df %>%
  filter(category == 'S04') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var01,Var02)) %>%
  head(1622)

df_s05 <- df %>%
  filter(category == 'S05') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var02,Var03)) %>%
  head(1622)

df_s06 <- df %>%
  filter(category == 'S06') %>%
  mutate(Date_index = row_number()) %>%
  select(c(Date_index,Date,Var05,Var07)) %>%
  head(1622)
```

{{< pagebreak >}}

# Overview

Praesent ac ipsum ut leo facilisis consequat. Sed aliquam odio vitae est volutpat, sed tincidunt eros imperdiet. Maecenas sit amet dictum massa. Cras ultricies neque lorem, in fermentum turpis venenatis nec. Aenean non diam interdum, tincidunt dui in, maximus orci.

Praesent eget enim id erat volutpat euismod. Vivamus euismod turpis nec sollicitudin accumsan. Duis maximus finibus auctor. Phasellus quis ornare nunc, id porttitor elit. Donec sit amet vulputate arcu. Nulla sodales lacinia nisl, sed hendrerit ex consectetur eget.

Vivamus euismod turpis nec sollicitudin accumsan. Duis maximus finibus auctor. Phasellus quis ornare nunc, id porttitor elit. Donec sit amet vulputate arcu. Nulla sodales lacinia nisl, sed hendrerit ex consectetur eget.

{{< pagebreak >}}

# Series One

Praesent ac ipsum ut leo facilisis consequat. Sed aliquam odio vitae est volutpat, sed tincidunt eros imperdiet. Maecenas sit amet dictum massa. Cras ultricies neque lorem, in fermentum turpis venenatis nec.

```{r data_s01}
s01 <- df %>%
  filter(category == 'S01') %>%
  select(c(SeriesInd,Var01,Var02)) %>%
  head(1622)

var01 <- df %>%
  select(c(SeriesInd,Var01)) %>%
  na.locf()

var02 <- df %>%
  select(c(SeriesInd,Var02)) %>%
  na.locf()
```

## Variables & Analysis

Series one used two variables, Var01 and Var02. It seems that for both there was little if any seasonality but where the data seemed to have 5 day intervals with scattered gaps. A work days per year pattern was used however I do not believe that there is a major correlation with these series since in most of decomposition at various frequencies showed large runs of wave motion remainders showing their may be some other pattern to the data. each variable had a few missing variables which were imputed where necessary being replaced with the most recent non-NA value before it.

**Variable 01** shows an upward trend through the time series with what seems to be plateaus at either end with the mid section appearing linear and two almost camel humps at either end of the linear phase.

```{r}
#| layout-ncol: 2
var01ts <- ts(s01$Var01, start = c(1,1), frequency=260)%>% na.locf()
autoplot(var01ts)

decompose(var01ts) %>%
  autoplot()
```

**Variable 02** shows a very slight downward trend but generally appears to be near white noise.

```{r}
#| layout-ncol: 2
var02ts <- ts(s01$Var02, start = c(1,1), frequency=260)%>%  na.locf()
autoplot(var02ts)

decompose(var02ts) %>%
  autoplot()
```

Both Var01 and Var02 showed a very high amount of correlation as seen with the lag plots with Var01 having near 1.0 correlation almost 40 points out and Var02 with many values hovering around 0.5.

```{r}
#| layout-ncol: 2
ggAcf(var01ts,40)
ggAcf(var02ts,40)
```

Because of the non seasonal pattern of the data we moved forward using the forecast function which implemented an STL+ETS method and SES with a tuned alpha variable. After comparing these forecasts with a 80/20 training/testing split with the last 20 on the last half we tested the forecast optimizing the MAPE. We found that in all cases the tuned alpha performed better so used this for the Forecast. we found the alpha values optimized at a=0.03 for Var01 and a=0.27.

```{r}
#| layout-ncol: 2

s01<-s01%>%na.locf()

var01ts <- ts(s01$Var01, start = c(1,1), frequency=260)%>% na.locf()

train1<-window(var01ts,end = 6)
test1 <- window(var01ts,start = 6.00001)

# ses(train, h=140, alpha = 0.7) %>%
#   autoplot()

forc1<-forecast(train1, h=325)

alpha <- seq(.01, .99, by = .01)
error1 <- NA
for(i in seq_along(alpha)) {
  fit1 <- ses(train1, alpha = alpha[i],h = 325)
  error1[i] <- MAPE(y_pred=fit1$mean,y_true=test1)
  #print(c(fit1$mean[i],test1[i]))
 # print(error1[i])
}

# print(error1)
# print("...forcast...")
# MAPE(y_pred=forc1$mean,y_true=test1)
# min(error1)

ses(train1, alpha = 0.03, h = 325) %>% 
  autoplot() +
  autolayer(var01ts)

forecast(train1, h=325) %>% 
  autoplot() + 
  autolayer(var01ts)

# min(error1)
# MAPE(y_pred=forc1$mean,y_true=test1)
```

```{r}
#| layout-ncol: 2

train2<-window(var02ts,end = 6)
test2 <- window(var02ts,start = 6.000001)

# ses(train, h=140, alpha = 0.7) %>%
#   autoplot()

forc2<-forecast(train2, h=325)

alpha <- seq(.01, .99, by = .01)
error2 <- NA

for(i in seq_along(alpha)) {
  fit2 <- ses(train2, alpha = alpha[i],
             h = 325)
  error2[i] <- MAPE(y_pred=fit2$mean,y_true=test2)
}

# print(error2)
# print("...forcast...")
# MAPE(y_pred=forc2$mean,y_true=test2)
# min(error2)

ses(train2, alpha = 0.27, h = 325) %>% 
  autoplot() +
  autolayer(var02ts)

forecast(train2, h=325) %>% 
  autoplot() + 
  autolayer(var02ts)

# min(error2)
# MAPE(y_pred=forc2$mean,y_true=test2)
```

## Model Selection & Forecasts

Since the SES models performed slightly better, these were chosen for the forecast.

```{r}
#| layout-ncol: 2
forcast_s01_var01 <- ses(var01ts, alpha = 0.03, h = 140)
# forcast_s01_var01$mean

ses(var01ts, alpha = 0.03, h = 325) %>% 
  autoplot() + 
  autolayer(var01ts)

forcast_s01_var02 <- ses(var02ts, alpha = 0.27, h = 140)
# forcast_s01_var02$mean

ses(var02ts, alpha = 0.03, h = 325) %>% 
  autoplot() +
  autolayer(var02ts)

```

{{< pagebreak >}}

# Series Two

For the second category we examined time series data for Variables 2 and 3.

## Variables

**Variable 02** seems to represent a product or activity with a high volume, approximately 40 million units per day! Overall there seems to be a gradually decreasing trend for this item, with neither seasonality nor long-term cyclic patterns detected. The presence of many extreme values for this variable could possibly interfere with the accuracy of our forecasts. In order to correct for these conditions while preserving as much information as possible, we chose to identify and smooth those 66 outliers with a linear interpolation.

```{r}
#| layout-ncol: 2

# v02
data_s02_v02 <- df_s02 %>%
  select(values=Var02)

ts_s02_v02 <- ts(data_s02_v02)

autoplot(ts_s02_v02)

# outliers
ts_s02_v02_out <- tsoutliers(ts_s02_v02)
ts_s02_v02_clean <- tsclean(ts_s02_v02)

autoplot(ts_s02_v02, series = 'Orig') +
  autolayer(ts_s02_v02_clean, series = 'Clean')
```

**Variable 03** seems to represent a product or activity with low volume, approximately 14 units per day. Overall there seems to be a steady trend for this item, with no seasonality detected. This dataset has only two missing values, and one notable extreme value toward the end of the series, smoothed here with a linear interpolation.

```{r}
#| layout-ncol: 2
#| 
# v03
data_s02_v03 <- df_s02 %>%
  select(values=Var03)

ts_s02_v03 <- ts(data_s02_v03)

autoplot(ts_s02_v03)

# missing data
ts_s02_v03 <- na_interpolation(ts_s02_v03)

# outliers
ts_s02_v03_out <- tsoutliers(ts_s02_v03)
ts_s02_v03_clean <- tsclean(ts_s02_v03)

autoplot(ts_s02_v03, series = 'Orig') +
  autolayer(ts_s02_v03_clean, series = 'Clean')
```

## Model Selection & Forecasts

To evaluate and select models, we created 80/20 train/test split and score performance using the Mean Absolute Percentage Error (MAPE) statistic.

The three models evaluated for Variable 02 were:

-   ARIMA(2,1,3) with drift
-   Holt (Damped)
-   Simple Exponential Smoothing (SES)

We selected the SES method for this forecast since it produced the smallest MAPE score (30.22).

Our resulting forecast for the next 140 days has a stable mean of approximately 20.7M units daily, but with a fairly large predictive interval.

```{r}
## v02
# split
split_idx <- floor(length(ts_s02_v02_clean)*.8)
split_h <- (length(ts_s02_v02_clean) - split_idx)
            
ts_s02_v02_train <- window(ts_s02_v02_clean, end = split_idx)

# auto.arima
ts_s02_v02_arima_fit <- auto.arima(ts_s02_v02_train, stepwise = FALSE)
ts_s02_v02_arima <- forecast(ts_s02_v02_arima_fit, h = split_h)

# holt (damped)
ts_s02_v02_holtd <- holt(ts_s02_v02_train, damped=TRUE, h = split_h)

# ses
ts_s02_v02_ses <- ses(ts_s02_v02_train, h = split_h)

# check residuals
# checkresiduals(ts_s02_v02_arima)
# checkresiduals(ts_s02_v02_holtd)
# checkresiduals(ts_s02_v02_ses)

# accuracy
ts_s02_v02_arima_acc <- accuracy(ts_s02_v02_arima, ts_s02_v02_clean)["Test set", "MAPE"] # 45.82757
# ts_s02_v02_holtd_acc <- accuracy(ts_s02_v02_holtd, ts_s02_v02_clean)["Test set", "MAPE"] # 30.29515
# ts_s02_v02_ses_acc <- accuracy(ts_s02_v02_ses, ts_s02_v02_clean)["Test set", "MAPE"] # 30.22492

# forecast
ts_s02_v02_forecast <- forecast(ts_s02_v02_ses, ts_s02_v02, h=140)
autoplot(ts_s02_v02_forecast) + 
  ggtitle('Series Two - Var 02: Forecast')

# export
forecast_s02_v02 <- ts_s02_v02_forecast$mean
```

The three models evaluated for Variable 03 were:

-   ARIMA(2,1,0)
-   Holt (Damped)
-   Simple Exponential Smoothing

We selected the ARIMA(2,1,0) method for this forecast since it produced the smallest MAPE score (16.19).

Our resulting forecast for the next 140 days has a stable mean of approximately 16.2 units daily, but with a fairly large predictive interval.

```{r}
## v03
# split
split_idx <- floor(length(ts_s02_v03_clean)*.8)
split_h <- (length(ts_s02_v03_clean) - split_idx)
            
ts_s02_v03_train <- window(ts_s02_v03_clean, end = split_idx)

# auto.arima
ts_s02_v03_arima_fit <- auto.arima(ts_s02_v03_train, stepwise = FALSE)
ts_s02_v03_arima <- forecast(ts_s02_v03_arima_fit, h = split_h)

# holt (damped)
ts_s02_v03_holtd <- holt(ts_s02_v03_train, damped=TRUE, h = split_h)

# ses
ts_s02_v03_ses <- ses(ts_s02_v03_train, h = split_h)

# check residuals
# checkresiduals(ts_s02_v03_arima)
# checkresiduals(ts_s02_v03_holtd)
# checkresiduals(ts_s02_v03_ses)

# accuracy
ts_s02_v03_arima_acc <- accuracy(ts_s02_v03_arima, ts_s02_v03_clean)["Test set", "MAPE"] # 16.19648 **
ts_s02_v03_holtd_acc <- accuracy(ts_s02_v03_holtd, ts_s02_v03_clean)["Test set", "MAPE"] # 16.29988
ts_s02_v03_ses_acc <- accuracy(ts_s02_v03_ses, ts_s02_v03_clean)["Test set", "MAPE"] # 16.28299

# forecast
ts_s02_v03_forecast <- forecast(ts_s02_v03_arima, ts_s02_v03, h=140)
autoplot(ts_s02_v03_forecast) + 
  ggtitle('Series Two - Var 03: Forecast')

# export
forecast_s02_v03 <- ts_s02_v03_forecast$mean
```

{{< pagebreak >}}

# Series Three

For the third category we examined time series data for Variables 5 and 7.

## Variables

**Variable 05** seems to represent a product or activity with low volume, approximately 76 units per day. Overall there seems to be a gradually increasing trend for this item with no seasonality detected. This does not appear to be a stationary dataset, but by examining the differenced time series were able to confirm the lack of autocorrelations and seasonality. We also identified and smoothed several outliers and missing values with a linear interpolation before modeling.

```{r}
#| layout-ncol: 2

# v05
data_s03_v05 <- df_s03 %>%
  select(values=Var05)

ts_s03_v05 <- ts(data_s03_v05)

autoplot(ts_s03_v05)

# missing data
ts_s03_v05 <- na_interpolation(ts_s03_v05)

# outliers
ts_s03_v05_out <- tsoutliers(ts_s03_v05)
ts_s03_v05_clean <- tsclean(ts_s03_v05)

# autoplot(ts_s03_v05, series = 'Orig') +
#   autolayer(ts_s03_v05_clean, series = 'Clean')

# autocorrelations
#ggAcf(ts_s03_v05_clean)
autoplot(diff(ts_s03_v05_clean))
acf(diff(ts_s03_v05_clean), main = "ACF of S03_Var05 Difference")
```

**Variable 07** seems to represent an almost-identical time series as Variable 05 - in fact, the two datasets are 98% corelated.  With some variation, the Variable 07 dataset is approximately 75 units higher than Variable 05 across the board, but appears to be similar in every other regard. 

```{r}
#| layout-ncol: 2
#| 
# v03
data_s03_v07 <- df_s03 %>%
  select(values=Var07)

ts_s03_v07 <- ts(data_s03_v07)

autoplot(ts_s03_v07)

# missing data
ts_s03_v07 <- na_interpolation(ts_s03_v07)

# outliers
ts_s03_v07_out <- tsoutliers(ts_s03_v07)
ts_s03_v07_clean <- tsclean(ts_s03_v07)

# autoplot(ts_s03_v07, series = 'Orig') +
#   autolayer(ts_s03_v07_clean, series = 'Clean')

# autocorrelations
# ggAcf(ts_s03_v07_clean)
# autoplot(diff(ts_s03_v07_clean))
# acf(diff(ts_s03_v07_clean), main = "ACF of S03_Var05 Difference")

correlation <- cor(ts_s03_v05, ts_s03_v07)
squared_correlation <- correlation^2 # 0.9984582

differences <- setdiff(ts_s03_v05, ts_s03_v07)
summary(differences)
```

## Model Selection & Forecasts

To evaluate and select models, we created 80/20 train/test split and score performance using the Mean Absolute Percentage Error (MAPE) statistic.

The three models evaluated for Variable 05 were: ARIMA(1,1,1) with drift, ETS, and Naive. We selected the Naive method for this forecast since it produced the smallest MAPE score (15.91).

Our resulting forecast for the next 140 days has a stable mean of approximately 130 units daily, but with a fairly large predictive interval.

```{r}
## v05
# split
split_idx <- floor(length(ts_s03_v05_clean)*.8)
split_h <- (length(ts_s03_v05_clean) - split_idx)
            
ts_s03_v05_train <- window(ts_s03_v05_clean, end = split_idx)

# auto.arima
ts_s03_v05_arima_fit <- auto.arima(ts_s03_v05_train, lambda='auto', stepwise = FALSE)
ts_s03_v05_arima <- forecast(ts_s03_v05_arima_fit, h = split_h)

# ets
ts_s03_v05_ets_fit <- ets(ts_s03_v05_train, lambda='auto')
ts_s03_v05_ets <- forecast(ts_s03_v05_ets_fit, h = split_h)

# naive
ts_s03_v05_naive <- naive(ts_s03_v05_train, h = split_h)

# check residuals
# checkresiduals(ts_s03_v05_arima)
# checkresiduals(ts_s03_v05_ets)
# checkresiduals(ts_s03_v05_naive)

# accuracy
ts_s03_v05_arima_acc <- accuracy(ts_s03_v05_arima, ts_s03_v05_clean)["Test set", "MAPE"] # 
ts_s03_v05_ets_acc <- accuracy(ts_s03_v05_ets, ts_s03_v05_clean)["Test set", "MAPE"] # 
ts_s03_v05_naive_acc <- accuracy(ts_s03_v05_naive, ts_s03_v05_clean)["Test set", "MAPE"] # 

# forecast
ts_s03_v05_forecast <- forecast(ts_s03_v05_naive, ts_s03_v05, h=140)
autoplot(ts_s03_v05_forecast) +
  ggtitle('Series Three - Var 05: Forecast')

# export
forecast_s03_v05 <- ts_s03_v05_forecast$mean
```

The three models evaluated for Variable 03 were ARIMA(3,1,2) with drift, ETS and Naive. We selected the Naive method for this forecast since it produced the smallest MAPE score (14.79).

Our resulting forecast for the next 140 days has a stable mean of approximately 128.5 units daily, but with a fairly large predictive interval.

```{r}
## v07
# split
split_idx <- floor(length(ts_s03_v07_clean)*.8)
split_h <- (length(ts_s03_v07_clean) - split_idx)
            
ts_s03_v07_train <- window(ts_s03_v07_clean, end = split_idx)

# auto.arima
ts_s03_v07_arima_fit <- auto.arima(ts_s03_v07_train, lambda='auto', stepwise = FALSE)
ts_s03_v07_arima <- forecast(ts_s03_v07_arima_fit, h = split_h)

# ets
ts_s03_v07_ets_fit <- ets(ts_s03_v07_train, lambda='auto')
ts_s03_v07_ets <- forecast(ts_s03_v07_ets_fit, h = split_h)

# naive
ts_s03_v07_naive <- naive(ts_s03_v07_train, h = split_h)

# check residuals
# checkresiduals(ts_s03_v07_arima)
# checkresiduals(ts_s03_v07_ets)
# checkresiduals(ts_s03_v07_naive)

# accuracy
ts_s03_v07_arima_acc <- accuracy(ts_s03_v07_arima, ts_s03_v07_clean)["Test set", "MAPE"] # 
ts_s03_v07_ets_acc <- accuracy(ts_s03_v07_ets, ts_s03_v07_clean)["Test set", "MAPE"] # 
ts_s03_v07_naive_acc <- accuracy(ts_s03_v07_naive, ts_s03_v07_clean)["Test set", "MAPE"] # 

# forecast
ts_s03_v07_forecast <- forecast(ts_s03_v07_naive, ts_s03_v07, h=140)
autoplot(ts_s03_v07_forecast) +
  ggtitle('Series Three - Var 07: Forecast')

# export
forecast_s03_v07 <- ts_s03_v07_forecast$mean
```

{{< pagebreak >}}

# Series Four

```{r data_s04}
df_s04 <- df %>%
  filter(category == 'S04') %>%
  select(c(Date,Var01,Var02)) %>%
  head(1622)
```

## Variables & Analysis

```{r}

```

## Model Selection & Forecasts

```{r}

```

{{< pagebreak >}}

# Series Five

```{r data_s05}
s05 <- df %>%
  filter(category == 'S05') %>%
  select(c(SeriesInd,Var02,Var03))%>%
  head(1622)
s05_var02 <- s05 %>%
  select(c(SeriesInd,Var02)) %>%
  na.locf()
s05_var03 <- s05 %>%
  select(c(SeriesInd,Var03)) %>%
  na.locf()
```

## Variables & Analysis

Series five consisted of two variables var02 and var03. both contained small amounts of missing values and where applicable were replaced based on the previous held value. Additionally since all of these data sets appear to be on a 5 day cycle the work year(260) days was used for establishing frequency.

Var02- In the variable 2 plots we see a gradual small decrease in value with an almost white noise looking fluctuation. It does not seem to show any seasonality as in the decomposition plots we found in most cases there were runs of remainders that formed an almost Wave like pattern.

Var03- variable 3 has what seems to be three patterns in the center of the plot there seems to be slow steady growth that is near linear with a fair amount of fluctuation. Additionally at the start of the data set there is a steep rise and at the end a steep fall. The seasonal patterns seem to make these more gradual however there is a good amount of wave motion in the remainders so there is an aspect of the data this is not accounted for despite the seasonal graph matching a few of the data motifs.

```{r}
#| layout-ncol: 2
s05_var02ts <- ts(s05_var02$Var02, start = c(1,1), frequency=260)%>% na.locf()
autoplot(s05_var02ts)

decompose(s05_var02ts) %>%
  autoplot()

s05_var03ts <- ts(s05_var03$Var03, start = c(1,1), frequency=260)%>%  na.locf()
autoplot(s05_var03ts)

decompose(s05_var03ts) %>%
  autoplot()

```

Both variable three and variable five show high levels of corelation within the lag plot with var02 hovering near 0.5-0.4 and var03 hovering around 1-0.8 for over 40 values.

```{r}
#| layout-ncol: 2
ggAcf(s05_var02ts,40)
ggAcf(s05_var03ts,40)
```

For this analysis we compared how the forcast() function performed using an STL+ETS model and how an SES(simply exponential smoothing) model with tuned alpha variable performed. We tuned the SES by using an algorithm to reduce MAPE to determine the alpha value. We found using the highest alpha=0.99 in both cases gave the most accurate forecast when testing on the last 20% of the data with an 80/20 training testing split and when we compared this to the forecast function performed slightly better.

```{r}
#| layout-ncol: 2

s05_var02ts <- ts(s05_var02$Var02, start = c(1,1), frequency=260) %>% 
  na.locf()

train25 <- window(s05_var02ts,end = 6)
test25 <- window(s05_var02ts,start = 6.000001)

# ses(train, h=140, alpha = 0.7) %>%
#   autoplot()

forc25 <- forecast(train25, h=325)

alpha <- seq(.01, .99, by = .01)
error25 <- NA
for(i in seq_along(alpha)) {
  fit25 <- ses(train25, alpha = alpha[i],
             h = 325)
  error25[i] <- MAPE(y_pred=fit25$mean,y_true=test25)
}

# print(error25)
# print("...forcast...")
# MAPE(y_pred=forc25$mean,y_true=test25)
# min(error25)

ses(train25, alpha = 0.99, h = 325) %>% 
  autoplot() + 
  autolayer(s05_var02ts)

forecast(train25, h=325) %>% 
  autoplot() +
  autolayer(s05_var02ts)

# autoplot(s05_var02ts)
#min(error25)
#MAPE(y_pred=forc25$mean,y_true=test25)

```

```{r}
#| layout-ncol: 2
train0503 <- window(s05_var03ts,end = 6)
test0503 <- window(s05_var03ts,start = 6.000001)

# ses(train, h=140, alpha = 0.7) %>%
#   autoplot()

forc0503 <- forecast(train0503, h=325)

alpha <- seq(.01, .99, by = .01)
error0503 <- NA
for(i in seq_along(alpha)) {
  fit0503 <- ses(train0503, alpha = alpha[i],
             h = 325)
  error0503[i] <- MAPE(y_pred=fit0503$mean,y_true=test0503)
}

# print(error0503)
# print("…forcast…")
# MAPE(y_pred=forc0503$mean,y_true=test0503)
# min(error0503)

ses(train0503, alpha = 0.99, h = 325) %>% 
  autoplot() +
  autolayer(s05_var03ts)

forecast(train0503, h=325) %>% 
  autoplot() + 
  autolayer(s05_var03ts)

# autoplot(s05_var03ts)
# min(error0503)
# MAPE(y_pred=forc0503$mean,y_true=test0503)
```

## Model Selection & Forecasts

Since the SES models performed slightly better these were chosen for the forecast.

```{r}
#| layout-ncol: 2
forcast_s05_var02<-ses(s05_var02ts, alpha = 0.99, h = 140)
# forcast_s05_var02$mean
autoplot(forcast_s05_var02)

forcast_s05_var03<-ses(s05_var03ts, alpha = 0.99, h = 140)
# forcast_s05_var03$mean
autoplot(forcast_s05_var03)

```

{{< pagebreak >}}

# Series Six

```{r data_s06}
df_s06 <- df %>%
  filter(category == 'S06') %>%
  select(c(Date,Var05,Var07)) %>%
  head(1622)
```

## Variables & Analysis

```{r}

```

## Model Selection & Forecasts

```{r}

```

{{< pagebreak >}}

# Conclusions

{{< pagebreak >}}

# Appendix

## R Code

```{r}
#| echo: true
#| eval: false

# code here
```
